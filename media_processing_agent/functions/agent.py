from typing import Dict, Any, List, Optional
import os
from dotenv import load_dotenv
from datetime import datetime, timezone

import json
import logging
import asyncio
import uuid
from google.cloud.aiplatform_v1beta1.types import index_endpoint
from vertexai.generative_models import GenerativeModel, Part
from vertexai.language_models import TextEmbeddingModel
import vertexai
from google.cloud import firestore
from google.cloud.aiplatform import MatchingEngineIndex
from google.cloud import storage

# Load environment variables
load_dotenv()


# Get environment variables
def get_project_id():
    return os.getenv("GOOGLE_CLOUD_PROJECT", "hackason-464007")


def get_location():
    return os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")


def get_index_id():
    return os.getenv("VERTEX_AI_INDEX_ID")


def get_index_endpoint_id():
    return os.getenv("VERTEX_AI_INDEX_ENDPOINT_ID")


# Initialize services lazily
_db = None
_embedding_model = None
_vector_search_index = None


def get_firestore_client():
    global _db
    if _db is None:
        _db = firestore.Client(project=get_project_id())
    return _db


def get_embedding_model():
    global _embedding_model
    if _embedding_model is None:
        vertexai.init(project=get_project_id(), location=get_location())
        _embedding_model = TextEmbeddingModel.from_pretrained("text-embedding-004")
    return _embedding_model


def get_vector_search_index():
    global _vector_search_index
    if _vector_search_index is None:
        index_id = get_index_id()
        if index_id:
            _vector_search_index = MatchingEngineIndex(
                index_name=f"projects/{get_project_id()}/locations/{get_location()}/indexes/{index_id}"
            )
    return _vector_search_index


logger = logging.getLogger(__name__)
MODEL_NAME = "gemini-2.5-flash"

# Child ID will be set when the agent is invoked
# Default to "demo" if not provided
CHILD_ID = "demo"


def convert_firebase_url_to_gs(firebase_url: str) -> str:
    """Convert Firebase download URL to gs:// format for better Vertex AI access"""
    try:
        # Extract bucket and object path from Firebase URL
        if "firebasestorage.app" in firebase_url and "/o/" in firebase_url:
            # Parse Firebase Storage download URL
            parts = firebase_url.split("/o/")
            if len(parts) >= 2:
                bucket_part = parts[0].split("/")[-1]  # Get bucket name
                object_part = parts[1].split("?")[0]  # Remove query parameters

                # URL decode the object path
                import urllib.parse

                object_path = urllib.parse.unquote(object_part)

                gs_url = f"gs://{bucket_part}/{object_path}"
                logger.info(f"Converted Firebase URL to gs:// format: {gs_url}")
                return gs_url
    except Exception as e:
        logger.warning(f"Failed to convert Firebase URL: {e}")

    return firebase_url  # Return original if conversion fails


def objective_analyzer(media_uri: str) -> dict:
    """Extract objective facts from media files"""
    model = GenerativeModel(MODEL_NAME)
    try:
        # Try to convert Firebase URL to gs:// format for better access
        original_uri = media_uri
        if "firebasestorage.app" in media_uri:
            media_uri = convert_firebase_url_to_gs(media_uri)

        # Determine MIME type from URL extension
        media_uri_lower = original_uri.lower()

        # Extract extension from URL (handle query parameters)
        url_path = media_uri_lower.split("?")[0]

        # Check common image formats
        if any(url_path.endswith(ext) for ext in [".jpg", ".jpeg"]):
            mime_type = "image/jpeg"
        elif url_path.endswith(".png"):
            mime_type = "image/png"
        elif url_path.endswith(".gif"):
            mime_type = "image/gif"
        elif url_path.endswith(".webp"):
            mime_type = "image/webp"
        elif url_path.endswith(".bmp"):
            mime_type = "image/bmp"
        # Check common video formats
        elif url_path.endswith(".mp4"):
            mime_type = "video/mp4"
        elif url_path.endswith(".avi"):
            mime_type = "video/x-msvideo"
        elif url_path.endswith(".mov"):
            mime_type = "video/quicktime"
        elif url_path.endswith(".webm"):
            mime_type = "video/webm"
        elif url_path.endswith(".mkv"):
            mime_type = "video/x-matroska"
        else:
            # Default to image/jpeg if can't determine
            mime_type = "image/jpeg"
            logger.warning(
                f"Could not determine MIME type from URL, defaulting to {mime_type}"
            )

        logger.info(f"Detected MIME type: {mime_type} for URL: {media_uri}")

        # Try gs:// URL first, then fallback to original URL
        try:
            media_part = Part.from_uri(uri=media_uri, mime_type=mime_type)
        except Exception as gs_error:
            logger.warning(f"gs:// URL failed, trying original URL: {gs_error}")
            media_part = Part.from_uri(uri=original_uri, mime_type=mime_type)

        prompt = """
        ã‚ãªãŸã¯ã€å†™çœŸã‚„å‹•ç”»ã‹ã‚‰ã‚·ãƒ¼ãƒ³ã‚’æ­£ç¢ºã«èª­ã¿å–ã‚‹åˆ†æã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
        ã“ã®ç”»åƒ/å‹•ç”»ã‹ã‚‰è¦³å¯Ÿã§ãã‚‹å…·ä½“çš„ãªã‚·ãƒ¼ãƒ³æƒ…å ±ã¨è¡Œå‹•äº‹å®Ÿã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚

        ã€åˆ†æã®é‡ç‚¹ã€‘
        - å­ä¾›ãŒã€Œä½•ã‚’ã—ã¦ã„ã‚‹ã‹ã€ã‚’å…·ä½“çš„ã«ç‰¹å®šã™ã‚‹
        - ãã®å ´ã®çŠ¶æ³ã‚„ç’°å¢ƒã‚’è©³ã—ãæå†™ã™ã‚‹
        - å­ä¾›ã®è¡¨æƒ…ã‚„å‹•ä½œã‚’å®¢è¦³çš„ã«è¨˜éŒ²ã™ã‚‹
        - æˆé•·ã‚„ç™ºé”ã®æ¨æ¸¬ã¯è¡Œã‚ãšã€è¦‹ãŸã¾ã¾ã‚’è¨˜è¿°ã™ã‚‹

        ã€å‡ºåŠ›å½¢å¼ã€‘
        {
            "scene_description": "ãã®å ´ã®ã‚·ãƒ¼ãƒ³å…¨ä½“ã®æå†™ï¼ˆå ´æ‰€ã€æ™‚é–“å¸¯ã€å‘¨ã‚Šã®çŠ¶æ³ãªã©ï¼‰",
            "child_actions": ["å­ä¾›ãŒè¡Œã£ã¦ã„ã‚‹å…·ä½“çš„ãªè¡Œå‹•ã®ãƒªã‚¹ãƒˆ"],
            "child_expressions": ["è¦³å¯Ÿã§ãã‚‹è¡¨æƒ…ã‚„æ„Ÿæƒ…è¡¨ç¾"],
            "objects_and_items": ["å­ä¾›ãŒè§¦ã‚Œã¦ã„ã‚‹ã€ä½¿ã£ã¦ã„ã‚‹ã€è¦‹ã¦ã„ã‚‹ç‰©ã®ãƒªã‚¹ãƒˆ"],
            "environment_details": ["èƒŒæ™¯ã€å ´æ‰€ã€å‘¨å›²ã®äººã‚„ç‰©ã®è©³ç´°"],
            "body_posture": ["å§¿å‹¢ã‚„ä½“ã®ä½ç½®ï¼ˆåº§ã£ã¦ã„ã‚‹ã€ç«‹ã£ã¦ã„ã‚‹ã€å¯ã¦ã„ã‚‹ãªã©ï¼‰"],
            "spoken_or_sounds": ["èã“ãˆã‚‹è¨€è‘‰ã€éŸ³ã€å£°ï¼ˆã‚ã‚‹å ´åˆï¼‰"],
            "clothing_and_appearance": ["æœè£…ã‚„èº«ã«ç€ã‘ã¦ã„ã‚‹ã‚‚ã®"]
        }
        """

        response = model.generate_content([media_part, prompt])
        response_text = response.text.strip()

        logger.info(f"Raw response from model: {response_text[:200]}...")

        import re

        json_match = re.search(r"```json\s*(.*?)\s*```", response_text, re.DOTALL)
        if json_match:
            response_text = json_match.group(1)
        else:
            json_match = re.search(r"\{.*\}", response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(0)

        response_text = response_text.strip()

        if not response_text:
            logger.error("Empty response from model")
            return {"status": "error", "error_message": "Empty response from model"}

        try:
            facts = json.loads(response_text)
            # Add media type to facts
            facts["media_type"] = "video" if mime_type.startswith("video/") else "image"
            return {"status": "success", "report": facts}
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON: {e}")
            logger.error(f"Response text: {response_text}")
            return {
                "status": "error",
                "error_message": f"Failed to parse JSON: {str(e)}",
            }

    except Exception as e:
        error_msg = str(e)

        # Check for URL access errors
        if (
            "Cannot fetch content from the provided URL" in error_msg
            or "URL_ERROR" in error_msg
        ):
            return {
                "status": "error",
                "error_message": "ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚Firebase Storageã®URLãŒVertex AIã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                "error_details": {
                    "original_error": error_msg,
                    "solutions": [
                        "Firebase Storageã®CORSè¨­å®šã‚’ç¢ºèªã™ã‚‹",
                        "Vertex AI Service Accountã«é©åˆ‡ãªæ¨©é™ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹",
                        "ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¬é–‹ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹Cloud Storageãƒã‚±ãƒƒãƒˆã®æ¨©é™ã‚’ç¢ºèªã™ã‚‹",
                    ],
                },
            }

        return {"status": "error", "error_message": str(e)}


def perspective_determiner(facts: Dict[str, Any], child_age_months: int) -> dict:
    """Determine analysis perspectives focused on scene identification and action description"""
    model = GenerativeModel(MODEL_NAME)
    try:
        facts_json = json.dumps(facts, ensure_ascii=False, indent=2)
        media_type = facts.get("media_type", "image")

        # å‹•ç”»ãƒ»å†™çœŸå…±é€šã§ã‚·ãƒ¼ãƒ³ç‰¹å®šã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹
        prompt = f"""
        ã‚ãªãŸã¯ã€å­ä¾›ã®è¡Œå‹•ã‚·ãƒ¼ãƒ³ã‚’ç‰¹å®šãƒ»åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
        è¦³å¯Ÿã•ã‚ŒãŸäº‹å®Ÿã‹ã‚‰ã€ã“ã®ãƒ¡ãƒ‡ã‚£ã‚¢ã§ã€Œå­ä¾›ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã‹ã€ã‚’å…·ä½“çš„ã«ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

        ã€å…¥åŠ›æƒ…å ±ã€‘
        ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—: {media_type}
        æœˆé½¢: {child_age_months}ãƒ¶æœˆ
        è¦³å¯Ÿã•ã‚ŒãŸäº‹å®Ÿ:
        {facts_json}

        ã€åˆ†æã®é‡ç‚¹ã€‘
        æˆé•·ã‚„ç™ºé”ã§ã¯ãªãã€ã€Œãã®ã¨ãå­ä¾›ãŒä½•ã‚’ã—ã¦ã„ãŸã‹ã€ã€Œã©ã‚“ãªã‚·ãƒ¼ãƒ³ã‹ã€ã®ç‰¹å®šã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚

        ã€åˆ†æè¦–ç‚¹ã®é¸æŠæŒ‡é‡ã€‘
        1. **è¡Œå‹•ã®ç‰¹å®š**
           - å­ä¾›ã®å…·ä½“çš„ãªå‹•ä½œã‚„è¡Œç‚º
           - ä½•ã‚’ã—ã¦ã„ã‚‹æœ€ä¸­ãªã®ã‹
           - ã©ã‚“ãªéŠã³ã‚„æ´»å‹•ã‚’ã—ã¦ã„ã‚‹ã‹

        2. **ã‚·ãƒ¼ãƒ³ã®èƒŒæ™¯**
           - ã©ã“ã§èµ·ãã¦ã„ã‚‹ã‚·ãƒ¼ãƒ³ã‹
           - ã©ã‚“ãªçŠ¶æ³ã‚„ç’°å¢ƒã‹
           - å‘¨å›²ã«ä½•ãŒã‚ã‚‹ã‹

        3. **è¡¨æƒ…ã‚„æ„Ÿæƒ…ã®ç¬é–“**
           - ãã®æ™‚ã®å­ä¾›ã®æ°—æŒã¡ã‚„åå¿œ
           - æ¥½ã—ãã†ã€çœŸå‰£ã€é©šã„ã¦ã„ã‚‹ãªã©
           - è¡¨æƒ…ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ãã®ç¬é–“ã®æ„Ÿæƒ…

        4. **ç‰©ã‚„äººã¨ã®é–¢ã‚ã‚Š**
           - ã©ã‚“ãªç‰©ã‚’ä½¿ã£ã¦ã„ã‚‹ã‹
           - èª°ã‹ã¨ä¸€ç·’ã«ã„ã‚‹ã‹
           - ä½•ã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹

        ã€å‡ºåŠ›å½¢å¼ã€‘
        {{
            "perspectives": [
                {{
                    "type": "è¦–ç‚¹åï¼ˆaction_focus, scene_context, emotional_moment, interaction_focusç­‰ï¼‰",
                    "focus": "ã“ã®è¦–ç‚¹ã§ç‰¹å®šã™ã¹ãå…·ä½“çš„ãªã‚·ãƒ¼ãƒ³ã‚„è¡Œå‹•",
                    "reason": "ãªãœã“ã®ã‚·ãƒ¼ãƒ³ãŒèˆˆå‘³æ·±ã„ã‹",
                    "observable_signs": ["ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰è¦³å¯Ÿã•ã‚ŒãŸå…·ä½“çš„ãªè¦ç´ "]
                }}
            ],
            "analysis_note": "ã“ã®ãƒ¡ãƒ‡ã‚£ã‚¢ãŒæ‰ãˆãŸã‚·ãƒ¼ãƒ³ã®æ¦‚è¦"
        }}
        """

        prompt += """
        
        ã€é‡è¦ã€‘
        - è¦–ç‚¹æ•°ã¯æœ€å¤§4ã¤ã¾ã§
        - å®Ÿéš›ã«è¦³å¯Ÿã•ã‚ŒãŸå†…å®¹ã«åŸºã¥ãè¦–ç‚¹ã®ã¿ã‚’é¸æŠ
        - å„è¦–ç‚¹ã¯é‡è¤‡ã—ãªã„ã‚ˆã†ã«ç‹¬ç«‹ã—ãŸè¦³ç‚¹ã‹ã‚‰é¸ã¶
        """

        response = model.generate_content(prompt)
        response_text = response.text.strip()

        logger.info(
            f"Raw response from perspective_determiner: {response_text[:200]}..."
        )

        # Extract JSON from response
        import re

        json_match = re.search(r"```json\s*(.*?)\s*```", response_text, re.DOTALL)
        if json_match:
            response_text = json_match.group(1)
        else:
            json_match = re.search(r"\{.*\}", response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(0)

        perspectives = json.loads(response_text)
        return {"status": "success", "report": perspectives}

    except Exception as e:
        logger.error(f"Error in perspective_determiner: {e}")
        return {"status": "error", "error_message": str(e)}


def dynamic_multi_analyzer(facts: Dict[str, Any], perspective: Dict[str, Any]) -> dict:
    """Analyze facts from a specific perspective"""
    model = GenerativeModel(MODEL_NAME)
    try:
        # Validate perspective structure
        if "type" not in perspective:
            return {
                "status": "error",
                "error_message": "perspective must contain 'type' field",
            }
        if "focus" not in perspective:
            return {
                "status": "error",
                "error_message": "perspective must contain 'focus' field",
            }

        facts_json = json.dumps(facts, ensure_ascii=False, indent=2)
        media_type = facts.get("media_type", "image")

        prompt = f"""
        ã‚ãªãŸã¯ã€å­ä¾›ã®ã‚·ãƒ¼ãƒ³ã‚„è¡Œå‹•ã‚’å…·ä½“çš„ã«æå†™ã™ã‚‹è¨˜éŒ²å°‚é–€å®¶ã§ã™ã€‚
        è¦³å¯Ÿã•ã‚ŒãŸäº‹å®Ÿã‹ã‚‰ã€æŒ‡å®šã•ã‚ŒãŸè¦–ç‚¹ã§ã€Œå­ä¾›ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã‹ã€ã‚’å…·ä½“çš„ã«æå†™ã—ã¦ãã ã•ã„ã€‚

        ã€å…¥åŠ›æƒ…å ±ã€‘
        ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—: {media_type}
        åˆ†æè¦–ç‚¹: {perspective['type']}
        ç€ç›®ãƒã‚¤ãƒ³ãƒˆ: {perspective['focus']}
        è¦³å¯Ÿã•ã‚ŒãŸäº‹å®Ÿ:
        {facts_json}

        ã€åˆ†æã®é‡ç‚¹ã€‘
        æˆé•·ã‚„ç™ºé”ã®è©•ä¾¡ã§ã¯ãªãã€ã€Œãã®ç¬é–“ã«å­ä¾›ãŒä½•ã‚’ã—ã¦ã„ãŸã‹ã€ã€Œã©ã‚“ãªã‚·ãƒ¼ãƒ³ã ã£ãŸã‹ã€ã®å…·ä½“çš„ãªæå†™ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚

        ã€æå†™ã®æŒ‡é‡ã€‘
        1. **å…·ä½“çš„ãªè¡Œå‹•ã®è¨˜éŒ²**: å­ä¾›ãŒå®Ÿéš›ã«è¡Œã£ã¦ã„ã‚‹å‹•ä½œã‚„è¡Œç‚ºã‚’è©³ã—ãæå†™
        2. **ã‚·ãƒ¼ãƒ³ã®æƒ…æ™¯æå†™**: ãã®å ´ã®é›°å›²æ°—ã€ç’°å¢ƒã€çŠ¶æ³ã‚’ç”Ÿãç”Ÿãã¨è¡¨ç¾
        3. **è¡¨æƒ…ã‚„åå¿œã®è¦³å¯Ÿ**: ãã®ç¬é–“ã®å­ä¾›ã®æ„Ÿæƒ…ã‚„è¡¨æƒ…ã‚’å®¢è¦³çš„ã«è¨˜éŒ²
        4. **æ¥½ã—ã„ç¬é–“ã®å¼·èª¿**: ãã®ã‚·ãƒ¼ãƒ³ã®é¢ç™½ã•ã‚„é­…åŠ›çš„ãªç‚¹ã‚’è¦ªã—ã¿ã‚„ã™ãè¡¨ç¾
        5. **æ¤œç´¢ã—ã‚„ã™ã„ã‚¿ã‚°**: å…·ä½“çš„ãªè¡Œå‹•ã‚„å ´é¢ã‚’è¡¨ã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ

        ã€å‡ºåŠ›å½¢å¼ã€‘
        {{
            "perspective_type": "{perspective['type']}",
            "title": "ãã®ã‚·ãƒ¼ãƒ³ã‚’è¡¨ã™å…·ä½“çš„ãªã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ15æ–‡å­—ä»¥å†…ï¼‰",
            "summary": "å­ä¾›ã®è¡Œå‹•ã¨ãã®æ™‚ã®çŠ¶æ³ã‚’å…·ä½“çš„ã«æå†™ï¼ˆ100æ–‡å­—ç¨‹åº¦ï¼‰",
            "content": "ãã®ã‚·ãƒ¼ãƒ³ã®è©³ã—ã„æå†™ã¨ã€ãªãœãã®ç¬é–“ãŒå°è±¡çš„ãªã®ã‹ã®èª¬æ˜",
            "scene_keywords": ["ãã®ã‚·ãƒ¼ãƒ³ã‚„è¡Œå‹•ã‚’è¡¨ç¾ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"],
            "vector_tags": ["å…·ä½“çš„ãªè¡Œå‹•ã‚„å ´é¢ã‚’è¡¨ã™ã‚¿ã‚°ã‚’5-8å€‹ã€‚ä¾‹ï¼šã€Œç©ã¿æœ¨ã§éŠã¶æ™‚é–“ã€ã€ŒãŠç¥­ã‚Šã‚’æ¥½ã—ã‚€å§¿ã€ã€Œæ°´éŠã³ã«å¤¢ä¸­ã€ã€ŒãŠã‚„ã¤ã‚¿ã‚¤ãƒ ã®ç¬‘é¡”ã€ãªã©ã€è¡Œå‹•ã‚„å ´é¢ãŒåˆ†ã‹ã‚‹10-20æ–‡å­—ç¨‹åº¦ã®ãƒ•ãƒ¬ãƒ¼ã‚º"]
        }}

        ã€æ³¨æ„äº‹é …ã€‘
        - æˆé•·ã®è©•ä¾¡ã‚„ç™ºé”ã®åˆ¤æ–­ã¯è¡Œã‚ãªã„
        - ã€Œã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€ãªã©ã®æ–­å®šçš„ãªè¡¨ç¾ã¯é¿ã‘ã‚‹
        - ãã®ç¬é–“ã®æ¥½ã—ã•ã‚„é­…åŠ›ã‚’ä¸­å¿ƒã«æå†™ã™ã‚‹
        - è¦ªãŒè¦‹ã¦ã€Œã“ã®ç¬é–“ç´ æ•µã ãªã€ã¨æ€ãˆã‚‹ã‚ˆã†ãªè¡¨ç¾ã‚’å¿ƒãŒã‘ã‚‹
        """

        response = model.generate_content(prompt)
        response_text = response.text.strip()

        # Extract JSON from response
        import re

        json_match = re.search(r"```json\s*(.*?)\s*```", response_text, re.DOTALL)
        if json_match:
            response_text = json_match.group(1)
        else:
            json_match = re.search(r"\{.*\}", response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(0)

        analysis = json.loads(response_text)
        return {"status": "success", "report": analysis}

    except Exception as e:
        logger.error(f"Error in dynamic_multi_analyzer: {e}")
        return {"status": "error", "error_message": str(e)}




def generate_emotional_title(episodes: List[Dict[str, Any]]) -> str:
    """Generate an emotional title for timeline display (15-20 chars)"""
    try:
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰å…·ä½“çš„ãªæƒ…å ±ã‚’åé›†
        locations = []
        actions = []
        emotions = []
        objects = []
        
        for episode in episodes:
            if isinstance(episode, dict):
                summary = episode.get("summary", "")
                tags = episode.get("tags", episode.get("vector_tags", []))
                
                # å ´æ‰€ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã®æŠ½å‡º
                for place in ["å…¬åœ’", "ãŠç¥­ã‚Š", "å®¶", "ãŠã†ã¡", "å¤–", "éƒ¨å±‹", "åº­", "æµ·", "å±±", "å·"]:
                    if place in summary:
                        locations.append(place)
                
                # å…·ä½“çš„ãªè¡Œå‹•ã®æŠ½å‡º
                for action in ["éŠã¶", "ç¬‘ã†", "èµ°ã‚‹", "æ­©ã", "é£Ÿã¹ã‚‹", "é£²ã‚€", "è¦‹ã‚‹", "æŒã¤", "è§¦ã‚‹"]:
                    if action in summary:
                        actions.append(action)
                
                # æ„Ÿæƒ…ã®æŠ½å‡º
                if "ç¬‘é¡”" in summary or "æ¥½ã—ã„" in summary or "å¬‰ã—ã„" in summary:
                    emotions.append("æ¥½ã—ã„")
                if "çœŸå‰£" in summary or "é›†ä¸­" in summary:
                    emotions.append("å¤¢ä¸­")
                
                # å…·ä½“çš„ãªç‰©ã®æŠ½å‡ºï¼ˆã‚¿ã‚°ã‹ã‚‰ï¼‰
                for tag in tags:
                    # ç‰©ã‚„å…·ä½“çš„ãªè¦ç´ ã‚’å«ã‚€ã‚¿ã‚°ã‚’æ¢ã™
                    if any(item in tag for item in ["ãƒœãƒˆãƒ«", "ãŠã‚‚ã¡ã‚ƒ", "æœ¬", "ãƒœãƒ¼ãƒ«", "ã„ã¡ã”", "é£Ÿã¹ç‰©"]):
                        objects.append(tag)
        
        # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        vertexai.init(project=get_project_id(), location=get_location())
        model = GenerativeModel(MODEL_NAME)

        
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’æŠ½å‡º
        combined_text = "\n".join([
            f"- {episode.get('summary', '')}" for episode in episodes if episode.get('summary')
        ])
        
        prompt = f"""
ã‚ãªãŸã¯ã€å­ä¾›ã®æ—¥å¸¸ã‚·ãƒ¼ãƒ³ã‚’é­…åŠ›çš„ã«è¡¨ç¾ã™ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®åˆ†æçµæœã‹ã‚‰ã€ã€Œãã®ç¬é–“ã«å­ä¾›ãŒä½•ã‚’ã—ã¦ã„ãŸã‹ã€ã‚’è¡¨ç¾ã™ã‚‹é­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æçµæœã®è¦ç´„ã€‘
{combined_text}

ã€ã‚¿ã‚¤ãƒˆãƒ«ä½œæˆã®é‡ç‚¹ã€‘
1. **å…·ä½“çš„ãªè¡Œå‹•ã‚„ã‚·ãƒ¼ãƒ³**: å­ä¾›ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã‹åˆ†ã‹ã‚‹ã‚ˆã†ã«
2. **ãã®å ´ã®é›°å›²æ°—**: æ¥½ã—ãã†ã€å¤¢ä¸­ã€ã®ã‚“ã³ã‚Šãªã©ã€ãã®æ™‚ã®æ§˜å­
3. **è¦ªã—ã¿ã‚„ã™ã•**: è¦‹ã‚‹äººãŒã»ã£ã“ã‚Šã™ã‚‹ã‚ˆã†ãªè¡¨ç¾

ã€é¿ã‘ã‚‹ã¹ãè¡¨ç¾ã€‘
- æˆé•·ã‚„ç™ºé”ã‚’å¼·èª¿ã™ã‚‹è¡¨ç¾ï¼ˆã€Œã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€ãªã©ï¼‰
- æŠ½è±¡çš„ã™ãã‚‹è¡¨ç¾

ã€è‰¯ã„ä¾‹ã€‘
- ã€Œç©ã¿æœ¨ã«å¤¢ä¸­ãªåˆå¾Œã€
- ã€ŒãŠç¥­ã‚Šã‚’æ¥½ã—ã‚€ç¬‘é¡”ã€
- ã€ŒãŠã‚„ã¤ã‚¿ã‚¤ãƒ ã®çœŸå‰£é¡”ã€
- ã€Œæ°´éŠã³ã§å¤§ã¯ã—ã‚ƒãã€

ã€ã‚¿ã‚¤ãƒˆãƒ«ã®æ¡ä»¶ã€‘
- ãã®ç¬é–“ã®è¡Œå‹•ã‚„ã‚·ãƒ¼ãƒ³ãŒåˆ†ã‹ã‚‹å…·ä½“çš„ãªè¡¨ç¾
- 15ã€œ20æ–‡å­—ç¨‹åº¦ã§ã€æœ€å¾Œã«å†…å®¹ã«åˆã£ãŸçµµæ–‡å­—ã‚’1ã¤ä»˜ã‘ã‚‹
- è¦ªãŒè¦‹ã¦ã€Œã“ã®ç¬é–“ã„ã„ãªã€ã¨æ€ãˆã‚‹ã‚ˆã†ãªè¡¨ç¾

ã€å‡ºåŠ›å½¢å¼ã€‘
ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿
"""
        
        response = model.generate_content(prompt)
        emotional_title = response.text.strip()
        
        return emotional_title
        
    except Exception as e:
        logger.error(f"Failed to generate emotional title: {e}")
        return "ğŸŒˆãã‚‡ã†ã®ã§ãã”ã¨"


def save_multi_episode_analysis(
    episodes: List[Dict[str, Any]],
    media_id: str = "",
    media_source_uri: str = "",
    child_id: str = "",
    child_age_months: int = 0,
    user_id: str = "",
    captured_at: datetime = None,
    thumbnail_url: str = None,
) -> dict:
    """Save multiple episodes as nested array in a single media document"""
    try:
        # Generate media_id if not provided
        if not media_id:
            media_id = str(uuid.uuid4())
            logger.info(f"Generated new media_id: {media_id}")

        # Use provided child_id or default
        if not child_id:
            child_id = globals().get("CHILD_ID", "demo")

        logger.info(f"Saving {len(episodes)} episodes for media: {media_id}")

        db = get_firestore_client()

        # Prepare episodes data
        episodes_data = []
        for episode in episodes:
            # Extract episode data
            if isinstance(episode, dict) and "report" in episode:
                ep_data = episode["report"]
            else:
                ep_data = episode

            # Create scene-focused episode structure
            episode_entry = {
                "id": str(uuid.uuid4()),
                "type": ep_data.get("perspective_type", ep_data.get("type", "general")),
                "title": ep_data.get("title", ""),
                "summary": ep_data.get("summary", ""),
                "content": ep_data.get("content", ep_data.get("summary", "")),
                "tags": ep_data.get("vector_tags", ep_data.get("tags", [])),
                "scene_keywords": ep_data.get("scene_keywords", []),
                "metadata": {
                    "scene_description": ep_data.get("scene_description", ""),
                    "perspective_type": ep_data.get("perspective_type", ""),
                },
                "created_at": datetime.now(timezone.utc),
            }
            episodes_data.append(episode_entry)

        # Generate emotional title for timeline
        emotional_title = generate_emotional_title(episodes_data)

        # Save all data in single document
        media_data = {
            "media_uri": media_source_uri,
            "child_id": child_id,
            "child_age_months": child_age_months,
            "user_id": user_id,
            "emotional_title": emotional_title,  # For timeline display
            "episodes": episodes_data,
            "episode_count": len(episodes_data),
            "captured_at": captured_at if captured_at else datetime.now(timezone.utc),  # Use provided captured_at or current time
            "created_at": datetime.now(timezone.utc),
            "updated_at": datetime.now(timezone.utc),
        }
        
        # Add thumbnail URL if provided (for videos)
        if thumbnail_url:
            media_data["thumbnail_url"] = thumbnail_url

        # Save to Firestore
        media_ref = db.collection("analysis_results").document(media_id)
        media_ref.set(media_data)

        logger.info(f"âœ… Successfully saved {len(episodes_data)} episodes for media: {media_id}")

        return {
            "status": "success",
            "media_id": media_id,
            "emotional_title": emotional_title,
            "episode_count": len(episodes_data),
            "episodes": episodes_data,
        }

    except Exception as e:
        logger.error(f"âŒ Failed to save episodes: {e}")
        return {
            "status": "error",
            "error_message": f"Failed to save episodes: {str(e)}",
        }




def index_episodes(
    episodes: List[Dict[str, Any]],
    media_id: str,
    child_id: str = "",
    captured_at: datetime = None,
) -> dict:
    """Index multiple episodes for vector search"""
    try:
        # Use provided child_id or default
        if not child_id:
            child_id = globals().get("CHILD_ID", "demo")

        vector_search_index = get_vector_search_index()
        if not vector_search_index:
            logger.warning("Vector search index not configured. Skipping indexing.")
            return {"status": "skipped", "message": "Vector indexing not configured"}

        indexed_count = 0
        for episode in episodes:
            try:
                # Extract episode data
                if isinstance(episode, dict) and "report" in episode:
                    ep_data = episode["report"]
                else:
                    ep_data = episode

                episode_id = ep_data.get("id", str(uuid.uuid4()))

                # Create text for embedding - tags only
                tags = ep_data.get("tags", [])
                if not tags:
                    logger.warning(f"No tags found for episode {episode_id}, skipping indexing")
                    continue

                embedding_text = " ".join(tags)

                # Generate embeddings
                embedding_model = get_embedding_model()
                embeddings = embedding_model.get_embeddings([embedding_text])

                if embeddings and len(embeddings) > 0:
                    embedding_vector = embeddings[0].values

                    # Create datapoint
                    datapoint_id = f"{media_id}_{episode_id}"
                    restricts = [
                        {"namespace": "media_id", "allow_list": [media_id]},
                        {"namespace": "child_id", "allow_list": [child_id]},
                    ]
                    
                    # Add captured_at timestamp if provided
                    if captured_at:
                        captured_at_timestamp = int(captured_at.timestamp())
                        restricts.append(
                            {"namespace": "captured_at", "value_int": captured_at_timestamp}
                        )
                    
                    datapoint = {
                        "datapoint_id": datapoint_id,
                        "feature_vector": embedding_vector,
                        "restricts": restricts,
                    }

                    # Upsert to index
                    vector_search_index.upsert_datapoints([datapoint])
                    indexed_count += 1
                    logger.info(f"Indexed episode {episode_id}")

            except Exception as e:
                logger.error(f"Failed to index episode: {e}")
                continue

        logger.info(f"âœ… Successfully indexed {indexed_count}/{len(episodes)} episodes")
        return {
            "status": "success",
            "indexed_count": indexed_count,
            "total_episodes": len(episodes),
        }

    except Exception as e:
        logger.error(f"âŒ Failed to index episodes: {e}")
        return {
            "status": "error",
            "error_message": f"Failed to index episodes: {str(e)}",
        }








def set_child_id(child_id: str = ""):
    """Set the child ID for the current session"""
    global CHILD_ID
    CHILD_ID = child_id if child_id else "demo"
    logger.info(f"Child ID set to: {CHILD_ID}")
    return CHILD_ID




def calculate_age_months(birth_date: datetime) -> int:
    """Calculate age in months from birthdate"""
    today = datetime.now(timezone.utc)
    months = (today.year - birth_date.year) * 12 + today.month - birth_date.month
    # Adjust if the day hasn't come yet this month
    if today.day < birth_date.day:
        months -= 1
    return max(0, months)  # Ensure non-negative


def generate_video_thumbnail_if_needed(media_uri: str) -> Optional[str]:
    """
    å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ ãƒã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç”Ÿæˆã™ã‚‹
    
    Args:
        media_uri: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®URIï¼ˆgs://ã¾ãŸã¯https://ï¼‰
        
    Returns:
        ã‚µãƒ ãƒã‚¤ãƒ«ã®URLï¼ˆç”Ÿæˆæ¸ˆã¿ã¾ãŸã¯æ–°è¦ç”Ÿæˆï¼‰ã€å¤±æ•—æ™‚ã¯None
    """
    try:
        # video_thumbnailãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from video_thumbnail import generate_video_thumbnail, get_thumbnail_path
        
        # URIã‹ã‚‰ãƒã‚±ãƒƒãƒˆåã¨ãƒ‘ã‚¹ã‚’æŠ½å‡º
        if media_uri.startswith('gs://'):
            # gs://bucket-name/path/to/file
            parts = media_uri[5:].split('/', 1)
            if len(parts) != 2:
                return None
            bucket_name, object_path = parts
        elif 'firebasestorage.googleapis.com' in media_uri or 'firebasestorage.app' in media_uri:
            # Firebase Storage URLã‹ã‚‰ãƒ‘ã‚¹ã‚’æŠ½å‡º
            import urllib.parse
            parsed = urllib.parse.urlparse(media_uri)
            path_parts = parsed.path.split('/o/')
            if len(path_parts) < 2:
                return None
            
            # ãƒã‚±ãƒƒãƒˆåã‚’æŠ½å‡º
            if 'firebasestorage.googleapis.com' in media_uri:
                bucket_name = parsed.path.split('/')[3]
            else:
                bucket_name = parsed.hostname.split('.')[0]
            
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’æŠ½å‡ºï¼ˆURLãƒ‡ã‚³ãƒ¼ãƒ‰ï¼‰
            object_path = urllib.parse.unquote(path_parts[1].split('?')[0])
        else:
            logger.warning(f"Unsupported media URI format: {media_uri}")
            return None
        
        # ã‚µãƒ ãƒã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
        thumbnail_path = get_thumbnail_path(object_path)
        
        # ã‚µãƒ ãƒã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        thumbnail_blob = bucket.blob(thumbnail_path)
        
        if thumbnail_blob.exists():
            logger.info(f"Thumbnail already exists: gs://{bucket_name}/{thumbnail_path}")
            return f"gs://{bucket_name}/{thumbnail_path}"
        
        # ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆè‡ªå‹•çš„ã«æœ€é©ãªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é¸æŠï¼‰
        logger.info(f"Generating thumbnail for: {media_uri}")
        thumbnail_url = generate_video_thumbnail(
            video_url=media_uri,
            bucket_name=bucket_name,
            output_path=thumbnail_path,
            time_offset=None  # è‡ªå‹•é¸æŠãƒ¢ãƒ¼ãƒ‰
        )
        
        return thumbnail_url
        
    except Exception as e:
        logger.error(f"Error in generate_video_thumbnail_if_needed: {str(e)}")
        return None


def get_child_age_months(child_id: str) -> int:
    """Get child's age in months from Firestore"""
    try:
        db = get_firestore_client()
        child_doc = db.collection("children").document(child_id).get()

        if child_doc.exists:
            child_data = child_doc.to_dict()
            birth_date = child_data.get("birthDate")

            if birth_date:
                # birthDate is a Firestore Timestamp
                return calculate_age_months(birth_date)

        logger.warning(f"Could not find birthDate for child_id: {child_id}")
        return 12  # Default to 12 months

    except Exception as e:
        logger.error(f"Error getting child age: {e}")
        return 12  # Default to 12 months


def process_media_for_cloud_function(
    media_uri: str,
    user_id: str = "",
    child_id: str = "",
    child_age_months: int = None,  # Auto-calculate if not provided
    captured_at: datetime = None,  # Media capture date/time
) -> Dict[str, Any]:
    """
    Cloud Functionsã‹ã‚‰å‘¼ã³å‡ºã›ã‚‹é–¢æ•°
    ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤šè§’çš„ã«åˆ†æã—ã€è¤‡æ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ä¿å­˜ã™ã‚‹
    """
    try:
        # Auto-calculate age if not provided
        if child_age_months is None and child_id:
            child_age_months = get_child_age_months(child_id)
            logger.info(
                f"Auto-calculated age for child {child_id}: {child_age_months} months"
            )
        elif child_age_months is None:
            child_age_months = 12  # Default if no child_id

        # Generate unique media ID
        media_id = str(uuid.uuid4())

        # 1. å®¢è¦³çš„äº‹å®Ÿã‚’åˆ†æ
        facts_result = objective_analyzer(media_uri)
        if facts_result.get("status") != "success":
            return facts_result

        facts = facts_result.get("report", {})
        
        # å‹•ç”»ã®å ´åˆã¯ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ç”Ÿæˆ
        thumbnail_url = None
        if facts.get("media_type") == "video":
            thumbnail_url = generate_video_thumbnail_if_needed(media_uri)
            if thumbnail_url:
                logger.info(f"Generated video thumbnail: {thumbnail_url}")

        # 2. æœˆé½¢ã«åŸºã¥ã„ã¦åˆ†æè¦–ç‚¹ã‚’æ±ºå®š
        perspectives_result = perspective_determiner(facts, child_age_months)
        if perspectives_result.get("status") != "success":
            return perspectives_result

        perspectives_data = perspectives_result.get("report", {})
        perspectives = perspectives_data.get("perspectives", [])

        if not perspectives:
            return {
                "status": "error",
                "error_message": "No perspectives determined for analysis",
            }

        logger.info(f"Determined {len(perspectives)} perspectives for analysis")

        # 3. å„è¦–ç‚¹ã‹ã‚‰ä¸¦è¡Œã—ã¦åˆ†æã‚’å®Ÿè¡Œ
        episodes = []
        for perspective in perspectives:
            analysis_result = dynamic_multi_analyzer(facts, perspective)

            if analysis_result.get("status") == "success":
                analysis_data = analysis_result.get("report", {})
                # Add perspective type to the analysis
                analysis_data["type"] = perspective["type"]
                analysis_data["perspective_type"] = perspective["type"]
                episodes.append(analysis_data)
                logger.info(f"âœ… Successfully analyzed perspective: {perspective['type']}")
            else:
                logger.error(f"âŒ Failed to analyze perspective {perspective['type']}: {analysis_result.get('error_message', 'Unknown error')}")

        if not episodes:
            return {
                "status": "error",
                "error_message": "Failed to generate any episodes",
            }

        # 4. Save all episodes in single document
        save_result = save_multi_episode_analysis(
            episodes=episodes,
            media_id=media_id,
            media_source_uri=media_uri,
            child_id=child_id,
            child_age_months=child_age_months,
            user_id=user_id,
            captured_at=captured_at,
            thumbnail_url=thumbnail_url,  # ã‚µãƒ ãƒã‚¤ãƒ«URLã‚’è¿½åŠ 
        )

        if save_result.get("status") != "success":
            return save_result

        # 5. Index all episodes for vector search
        index_result = index_episodes(
            episodes=save_result.get("episodes", []),
            media_id=media_id,
            child_id=child_id,
            captured_at=captured_at,
        )

        # Return comprehensive result
        return {
            "status": "success",
            "media_id": media_id,
            "emotional_title": save_result.get("emotional_title", ""),
            "child_age_months": child_age_months,
            "episode_count": len(episodes),
            "indexed_count": index_result.get("indexed_count", 0),
            "perspectives": [ep["type"] for ep in episodes],
            "analysis_note": perspectives_data.get("analysis_note", ""),
        }

    except Exception as e:
        logger.error(f"Error processing media: {str(e)}")
        return {"status": "error", "error_message": str(e)}


# Cloud Functions ã§ã¯ ADK Agent ã¯ä½¿ç”¨ã—ãªã„
